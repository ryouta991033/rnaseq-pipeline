################################
# workflow/Snakefile
# Docker安定版 + plots統合版 + S3同期修正版
################################

import os
import pandas as pd
import glob

configfile: "config/config.yaml"

# -----------------------------
# サンプル読み込み
# -----------------------------
samples = pd.read_csv("samples.tsv", sep="\t")
SAMPLES = samples["sample"].tolist()

SE_SAMPLES = samples.query("layout == 'SE'")["sample"].tolist()
PE_SAMPLES = samples.query("layout == 'PE'")["sample"].tolist()

# -----------------------------
# FastQ 自動探索
# -----------------------------
def fq1(wildcards):
    sample = wildcards.sample
    files = glob.glob(f"data/fastq/{sample}/*.fastq.gz")
    if not files:
        raise ValueError(f"No FastQ file found for sample {sample}")
    for f in files:
        if "R1" in f or "r1" in f or len(files) == 1:
            return f
    return files[0]

def fq2(wildcards):
    sample = wildcards.sample
    files = glob.glob(f"data/fastq/{sample}/*.fastq.gz")
    return [f for f in files if "R2" in f or "r2" in f]

# -----------------------------
# ルール読み込み
# -----------------------------
include: "rules/trim.smk"
include: "rules/build_index.smk"
include: "rules/align.smk"
include: "rules/count.smk"
include: "rules/plots.smk"   # ← 可視化統合

# -----------------------------
# mapperに応じたindex指定
# -----------------------------
MAPPER = config.get("mapper", "star")

if MAPPER == "star":
    INDEX_TARGET = "results/reference/STAR_index/Genome"
elif MAPPER == "hisat2":
    INDEX_TARGET = "results/reference/hisat2_index/genome.1.ht2"
else:
    raise ValueError(f"Unsupported mapper: {MAPPER}")

# -----------------------------
# S3設定
# -----------------------------
AWS_BUCKET = config["aws"]["bucket"]
AWS_PREFIX = config["aws"]["results_prefix"]

RUN_LOG = "results/snakemake_run.log"
STATS_FILE = "results/snakemake_stats.json"

# -----------------------------
# S3同期
# -----------------------------
rule sync_s3:
    input:
        # DESeq2出力
        "results/deseq2/DESeq2_results_all.csv",
        "results/deseq2/DESeq2_results_significant.csv",

        # plots出力（新構成）
        "results/plots/PCA_plot.png",
        "results/plots/volcano_plot.pdf",
        "results/plots/heatmap.pdf"
    output:
        "results/.s3_sync_done"
    shell:
        r"""
        set -euo pipefail

        echo "[INFO] Syncing results..."
        aws s3 sync results \
            s3://{AWS_BUCKET}/{AWS_PREFIX}/results \
            --delete

        if [ -d ".snakemake/log" ]; then
            aws s3 sync .snakemake/log \
                s3://{AWS_BUCKET}/{AWS_PREFIX}/snakemake_logs \
                --delete
        fi

        if [ -f "{RUN_LOG}" ]; then
            aws s3 cp {RUN_LOG} \
                s3://{AWS_BUCKET}/{AWS_PREFIX}/snakemake_run.log
        fi

        if [ -f "{STATS_FILE}" ]; then
            aws s3 cp {STATS_FILE} \
                s3://{AWS_BUCKET}/{AWS_PREFIX}/snakemake_stats.json
        fi

        touch {output}
        """

# -----------------------------
# rule all
# -----------------------------
rule all:
    input:
        # index
        INDEX_TARGET,

        # BAM
        expand("results/bam/{sample}.bam", sample=SAMPLES),
        expand("results/bam/{sample}.bam.bai", sample=SAMPLES),

        # counts
        "results/counts/gene_counts.txt",

        # DESeq2
        "results/deseq2/DESeq2_results_all.csv",
        "results/deseq2/DESeq2_results_significant.csv",

        # plots（新構成）
        "results/plots/PCA_plot.png",
        "results/plots/volcano_plot.pdf",
        "results/plots/heatmap.pdf",

        # S3完了フラグ
        "results/.s3_sync_done"
